---
title: "Ancianos"
author: "Ferran Garcia"
date: "`r Sys.Date()`"
output: 
  bookdown::pdf_document2:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warnings = FALSE, message = FALSE, fig.pos = "H")
setwd("C:/Users/ferran/Documents/Universitat/US/GEO/trabajos/ancianos")
```

```{r}
library(knitr)
library(corrplot)
library(dplyr)
library(readxl)
library(psych)
```

```{r}
source("scripts/import.R")
source("scripts/tabs.R")
```

\newpage
# Introducción

## Contexto

El envejecimiento demográfico emerge como un fenómeno geográfico crítico que podría acarrear serias implicaciones macroeconómicas estructurales en nuestra sociedad. En consecuencia, resulta imperativo abordar de manera inmediata políticas orientadas a mejorar la calidad de vida de la población mayor, fundamentadas en estudios que delineen su situación espacial y social, particularmente en aquellos entornos urbanos donde su presencia es más significativa.

## Objetivos

En el actual escenario, nos enfrentamos al desafío de localizar áreas urbanas en el municipio de Sevilla que compartan una estructura demográfica similar, especialmente en lo que respecta a la población mayor. Para abordar este objetivo, emplearemos distintos métodos de análisis estadístico multivariante y espacial. La meta es desarrollar servicios sociales y de asistencia que tomen en cuenta las características específicas de los ancianos y su distribución geográfica en la ciudad. En este contexto, nuestro enfoque consiste en identificar segmentos homogéneos de la población anciana en áreas urbanas. La ejecución de este proceso nos permitirá diseñar servicios sociales y de asistencia que se adapten a las necesidades particulares de los ancianos, considerando tanto su tipología como su ubicación en la ciudad.

## Estructura

\newpage
# Metodología

## Técnicas

## Herramientas

\newpage
# Reducción dimensional

Disponemos de muchas variables, eso motiva las técnicas de reducción dimensional. Usaremos análisis factorial de componentes pricipales, la idea es sintetizar todas las medidas disponibles en variables latentes. Lo haremos aprovechando la correlación que comparten. Para ello seleccionamos las variables que incluiremos a partir de un breve análisis exploratorio. Luego comprobaremos si es pertinente usar los procedimientos en cuestión en el conjunto de datos resultante. Entonces realizaremos varios ajustes con diferente número de factores hasta alcanzar la descomposición más satisfactoria en términos de representabilidad de las variables iniciales. Finalmente aplicaremos técnicas de rotación con tal de lograr factores ortogonales que sean interpretables. Con éstos extraeremos las puntuaciones factoriales que más adelante usaremos para crear clústers.

## Selección de variables y adecuación de los datos

La selección de variables sirve para subsanar potenciales problemas y afinar en el cálculo de factores. Es importante tanto para que se pueda realizar el análisis factorial como para que éste sea eficiente y se ajuste un modelo robusto con interpretación relativamente simple evitando sobreajuste.

Por ejemplo, si nos fijamos en las variables demográficas veremos que se incluyen múltiples medidas de población quedando algunas determinadas completamente por el resto. En cuanto a la *situación laboral* tenemos población activa, ocupada, inactiva y parados.Entonces el total queda determinado por otra variable, ya sea la población total o u subgrupo de ésta y por tanto son linealmente dependientes. Por tanto la matriz de correlaciones no será inverible y en consecuencia no se podrá realizar el análisis factorial. Lo mismo ocurre con algunas variables del estado de las viviendas. En el annexo se muestra una lista completa de las variables que han sido excluidas por este motivo.

Por otro lado es importante que las variables seleccionadas estén correlacionadas entre sí. Para comprobarlo representamos gráficamente la correlación entre las variables seleccionadas y recogemos en una tabla estadísticos relevantes para la selección de variables como: 

  - Estimación inicial de comunalidades^[Correlación múltiple al cuadrado]
  - Suma de correlaciones absolutas
  - Número de variables no correlacionadas^[Test de correlación de Pearson, nivel de significación del 5%]

Las variables que se muestran en la tabla quedan excluidas del análisis factorial.

```{r}
#| fig.cap = "Se muestran las variables con una comunalidad estimada menor al 70%,
#|  menos de 30 correlaciones no significativas al 5% y una suma de correlaciones absolutas menor a su mediana."
cor_tab0
```

```{r, out.width="100%", fig.align='center'}
#| fig.cap = "Correlaciones entre todas las variables."
include_graphics("grafs/cor/cor_x0.png")
```

Veamos ahora si el conjunto de datos seleccionados resulta apropiado para el análisis factorial o si debemos seleccionar variables con un criterio más estricto. Para ello realizamos varios tests:

**Esfericidad de Barlett:**

- Hipóteis nula: La matriz de correlaciones es la identidad (no existe ninguna correlación)
- Bajo $H_0$ el estadístico de contraste sigue una $\chi^2$, asintóticamente
- Disponemos de más de 400 observaciones, se sostiene la suposición asintótica

```{r, echo = TRUE}
cortest.bartlett(R1, n = nrow(X1))[["p.value"]] # podemos rechazar H_0
```

**Kaiser, Meyer, Olkin:**

- Medida de adecuación de la muestra para un análisis factorial
- Compara la suma de cuadrados de la "imagen" de la matriz de correlaciones con la original
- Está acotada entre 0 y 1, según Kaiser:
    + Valores mayores a 0,9 son maravillosos
    + Valores mayores a 0,8 son meritorios
    + Valores mayores a 0,7 son medios
    + Valores mayores a 0,6 son mediocres
    + Valores mayores a 0,5 son miserables
    + Valores menores a 0,5 son inaceptables

```{r, echo = TRUE}
KMO(R1)[[1]] # según Kaiser, la adecuación de la muestra es meritoria
```

Cabe remarcar que tras decidir que el análisis factrial es adecuado una práctica habital es estandarizar las variables con con propósito de comparabilidad entre ellas. Sin embargo trs realizar pruebas con y sin estandarizar hemos obtenido mejores resultados sin estandarizar. Teniendo en cuenta que la extracción de factores nos servirá fara formar clústers, que es nuestro principal objetivo consideramos más importante conseguir un buen ajuste que obtener comparabilidad en una etapa intermedia del trabajo.

\newpage
## Número, rotación y puntuaciones factoriales

Ahora nuestra intención es identificar una estructura latente dentro del conjunto de datos. Se focaliza el interés en los factores capaces de explicar una proporción significativa de la variabilidad presente en los datos. Para determinar cuántos factores debemos retener, empleamos dos criterios. En primer lugar, se puede dibujar un scree plot para evaluar los *eigenvalues* de los factores estimados. Además, aplicamos la Regla de Kaiser, que sugiere retener aquellos factores cuyos *eigenvalues* superen la unidad. Otra estrategia consiste en seleccionar tantos factores como sean necesarios para explicar alrededor de un 70% de la variabilidad de los datos.

**Regla de Kaiser:**

En el ámbito del álgebra una matriz (como la de correlaciones) se puede interpretar como una transformación lineal. Los *eigenvectors* asociados a una transformación son aquellos vectores cuya dirección es invariable a la misma y los *eigenvalues* aparejados son la medida en la que la dirección se alarga o mengua en magnitud. Bajo ciertas condiciones de regularidad estos vectores forman una base sobre la que se puede descomponer la transformación en cuestión. La idea de Kaiser es tomar tantos factores como autovectores de "alarguen" (su importancia crezca) en el proceso de descomposición.^[Para más información sobre los *eigenvectors* y *eigenvalues* consultar [este enlace](https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors)]

```{r, echo = TRUE}
autov_1 = eigen(R1)[["values"]]; sort(autov_1, decreasing = T) %>% round(digits = 2)
sum(autov_1 > 1) # según el criterio de Kaiser, usaremos 8 factores
```
En este caso Kaiser recomienda tomar 8 factores. No obstante los últimos están muy cerca de 1, es algo que debemos tener en cuenta para la selección del número de factores.

**Proporción de la varianza explicada:**

Para emplear el método de la varianza explicada por factores necesitamos realizar un análisis factorial como tal. De manera que ajustamos un modelo co un número arbitrario de factores y comprobamos cuántos son necesarios 

```{r, echo = TRUE}
fit_1 = factanal(na.omit(X1[,-1]), factors = 10, lower = .01)
fit_1[["loadings"]]
```

Esta salida muestra por un lado las cargas factoriales de cada variable inicial y por el otro la proporción de varianza explicada por cada uno de los factores. Nos interesa la parte final. Nos fijamos en que se explica alrededor del 70% de la varianza con 7 u 8 factores. También notamos que los primeros factores recogen sustancialmente más varianza que el resto.

**Scree plot:**

En este caso interpretamos gráficamente los *eigenvalues* asociados a factores con el número que usamos. Notamos que los cuatro primeros son relativamente más altos a los dos siguientes, que resultan ser los últimos que superan el umbral de 1. En este caso el gráfico sugiere usar alrededor de 6 factores.

```{r, echo = TRUE}
scree(X1[,-1], pc = FALSE)
```

**Interpretación en conjunto:**

Los diversos métodos indican una cantidad de factores similar: Entre 6 y 8. Puesto que utilizar 7 factores concuerda con los resultados de los diferentes criterios y está enmedio de las sugerencias de cada uno usaremos 7 factores para reducir la dimensionalidad de los datos.

```{r, echo = TRUE}
fit_2 = factanal(na.omit(X1[,-1]), factors = 7, lower = .007, nstart)
```

*breve interpretación de los factores*

\newpage
# Clústers

## Método jerárquico

## Método de k-medias

\newpage
# Annexo

## Variables excluidas

### Variables demográficas
- Categoría de edad: 60-64 años
- Sexo: Población masculina
- Procedencia: Provincial
- Nivel de estudios: Segundo grado
- Situación laboral: Activos
- Situación de actividad: Ocupados
- Categoría profesional: Servicios
- Posición profesional: Empleados
- Temporalidad profesional: Otro
- Residencia: Alojamiento


### Variables de la vivienda
- Tamaño en m^2: +120
- Número de habitaciones: 3
- Número de ocupantes: 3
- Año de construcción: 41-60
- Régimen legal: Otro

## Gráficos

### Correlaciones

```{r, out.width="100%", fig.align='center'}
#| fig.cap = "Correlaciones entre variables demográficas."
include_graphics("grafs/cor/cor_pob.png")
```

```{r, out.width="100%", fig.align='center'}
#| fig.cap = "Correlaciones entre variables de las viviendas."
include_graphics("grafs/cor/cor_casa.png")
```

```{r, out.width="100%", fig.align='center'}
#| fig.cap = "Correlaciones entre todas las variables."
include_graphics("grafs/cor/cor_df.png")
```


\newpage
# Bibliografía

- [Datos vectoriales](https://www.juntadeandalucia.es/institutodeestadisticaycartografia/dega/datos-espaciales-de-referencia-de-andalucia-dera/descarga-de-informacion)

- [Análisis clúster I](https://spatialanalysis.github.io/workshop-notes/spatial-clustering.html#clustering-analysis-with-other-r-packages) 

- [Análisis clúster II](https://spatialanalysis.github.io/tutorials/#cluster-analysis-in-r)

- [Análisis clúster III](https://mhahsler.github.io/Introduction_to_Data_Mining_R_Examples/book/clustering-analysis.html)

- [ClustGeo](https://cran.r-project.org/web/packages/ClustGeo/vignettes/intro_ClustGeo.html)

- [ClusterR](https://cran.r-project.org/web/packages/ClusterR/vignettes/the_clusterR_package.html)
